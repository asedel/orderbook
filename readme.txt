Notes:

1. netcat would not work for UDP on my machine ( Mac OS X 10.14.6 ) which both wasted significant time trying to get working and made it impossible for me to implement and test the UDP based listener.  However this piece of the code is relatively trivial and just subsists of listening into a buffer of reasonable size, tokenizing the incoming string by lines, and calling the lines iteratively into a handler.

2. the publishing spec is actual contradictory and broken. It doesn't specify that ANYTHING should be published for Cancels ( other than potentially indirect changes to Top of Book, however in scenario 15 which is the only scenario provided using cancels there are some "C" type messges in the expected output which is not explained, further more they are placed before the acknowledgements which is further contradictory and confusing.

3. the output format doesn't clearly specify whether multiple TOB changes should be delivered for a given message or not. This vagueness yields vastly complicated and unneeded complexity into the work to manage the book.  That said with sufficient time it is solvable as you could build a stack of messages and simply post process them at the end of processing a given "message" and remove all but the final TOB message for each side.

4. my makefile is setup for my mac, on your own machine you will likely want to take out the CXX=g++-10 as I had to manually override the compiler on my mac to use the GCC toolchain instead of Clang so that I could do things more sensibly.  Had I more time I would have cleaned up the makefile significantly but this makefile is simple enough to do the job.  The other noteworthy piece is that I added to the CXXFLAGS the prefix for where the boost libraries are installed on my system by Brew.  This Include path will vary based upon your host.  Sadly boost does NOT make use of pkg_config which I have long since opened a request to them to implement so that Make can locate boost by version from within the makefile itself without having to hardcode it based upon outside knowledge.

5. I have spent quite a bit of time on the pooling allocator and the book logic for performance as I have a background in this area, and my reference to the skip list comes from a real world application which I had to apply for handling books in the space of cryptocurrencies where there are often resting orders at absurd prices that will never execute that exist every day like a bid for $1 for 100 BTC or an offer for 1,000,000$ or more for 1 BTC.  These sit in the book and do nothing.  I performed rigorous research across several crypto exchanges in 2018, determining that over 90% of the activity in the book for a large group of private clients was constrained to the inner 64 levels ( and this included orders routed to me from a leading retail platform for cryto trading I can't name ).  Granted I havent been able to look at that code for over a year from my non-compete and was sure not to include anything propietary, and did some search to make sure that most of the techniques I used were publicly available, which again took time away as I wanted to be careful here.

6.  By writing initially so i could use text input it made it much easier to consume modified versions of your input.csv to run as tests, which in this case served more efficiently for unit testing than hand translating all of the given use cases into explicit code, they will only run slightly faster in the code format, and that wasnt a good use of my time even though unit testing was prioritized above some of the other bonuses.  exhaustive unit tests for this code would be a substantial endeavor taking well over a day to accomplish.  The basic gist is that I would use the mutator functions i introduced so as to configure objects and books that would be the resulting state of carrying out various actions.  The strategy would be to start by testing the level functions, and then afterwards the book management functions from orderbook, and then finally the top level cases via bookmanager.  in reality book manager just needs to verify that it passes its calls through and the switch statement is sane and the order destruction works right, as the bulk of the logic really lives and has testing in ordermanager.

orderparser is quite simple to test.

7. it is not specified what should haappen to a number of edge cases, for example what if non-integer inputs are given, what if the user uses duplicate userorderid's for new orders, what happens if they add a market order when there is no oppposing side? There is no message to be given, so I denoted a message to std:err for that case as well as several others.  It's also not clear whether a market order should be sweeping multiple levels or not. I assumed that a market order should consume as much quantity as possible which means that it could go across levels. Unfortunately this provides quite an inconveniance to my model for notifications regarding TOB changes currently as it means I cant simply fire them whenever it changes ( i assume yuo want them coalesced ).

8. luckily we have a single producer / consumer so it is fairly straightforward to put together a wait-free circular queue for the message logging

9. architectuarlly i would thus have 3 threads:
   1. asio udp network receiver, putting messages into a circular waitfree queue, each element would be granted a generous a very generous buffer sized by size of Order with 20 characters saved for the symbol name. I would transform the message into the tighter 'Order' format before buffering the messages.
   2. work thread pops "Order" messages off the CWQ and processes them, in turn its outgoing publish messages would be written to a second CWQ sized for perhaps 128 byte messages of text which should be long enough for the longest message it would have to deliver
   3. logger thread that pops messages off the second CWQ and writes them to the output file.
